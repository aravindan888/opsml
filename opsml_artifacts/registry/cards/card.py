from functools import cached_property
from typing import Any, Dict, List, Optional, Union, cast

import numpy as np
from cryptography.fernet import Fernet

# from onnx.onnx_ml_pb2 import ModelProto  # pylint: disable=no-name-in-module
import pandas as pd
from pyarrow import Table
from pydantic import BaseModel, validator
from pyshipt_logging import ShiptLogging

from opsml_artifacts.drift.data_drift import DriftReport
from opsml_artifacts.registry.sql.records import DataRegistryRecord, ModelRegistryRecord, ExperimentRegistryRecord
from opsml_artifacts.registry.cards.storage import save_record_artifact_to_storage
from opsml_artifacts.registry.data.formatter import ArrowTable, DataFormatter
from opsml_artifacts.registry.data.splitter import DataHolder, DataSplitter
from opsml_artifacts.registry.model.types import DataDict, ModelDefinition
from opsml_artifacts.registry.cards.predictor import OnnxModelPredictor
from opsml_artifacts.registry.sql.sql_schema import engine, Session, TableSchema, ArtifactTableNames

logger = ShiptLogging.get_logger(__name__)


class DataRegistryChecker:
    def __init__(self, model_registry_name: str):
        self._session = Session()

        data_table_name = self._get_data_table_name(model_registry_name=model_registry_name)
        self._table = TableSchema.get_table(table_name=data_table_name)
        self._create_table()

    def _create_table(self):
        self._table.__table__.create(bind=engine, checkfirst=True)

    def _get_data_table_name(self, model_registry_name: str) -> str:
        if ArtifactTableNames.TEST_MODEL_REGISTRY.name == model_registry_name:
            return ArtifactTableNames.TEST_DATA_REGISTRY.name
        return ArtifactTableNames.DATA_REGISTRY.name

    def validate_data_uid(self, uid: str):

        record = self._session.query(self._table.uid).filter(self._table.uid == uid).scalar()
        if record is None:
            return False
        return True


class ArtifactCard(BaseModel):
    """Base pydantic class for artifacts"""

    class Config:
        arbitrary_types_allowed = True
        validate_assignment = False

    def create_registry_record(self, registry_name: str, uid: str, version: int) -> Any:
        """Creates a registry record from self attributes

        Args:
            registry_name (str): Name of registry
            uid (str): Unique id associated with artifact
            version (int): Version for artifact
        """


class DataCard(ArtifactCard):
    """Create a DataCard from your data.

    Args:
        data (np.ndarray, pd.DataFrame, pa.Table): Data to use for
        data card.
        name (str): What to name the data
        team (str): Team that this data is associated with
        user_email (str): Email to associate with data card
        drift_report (dictioary of DriftReports): Optional drift report generated by Drifter class
        dependent_vars (List[str]): Optional list of dependent variables in data
        feature_descriptions (Dictionary): Optional dictionary of feature names and their descriptions
        data_splits (List of dictionaries): Optional list containing split logic. Defaults
        to None. Logic for data splits can be defined in the following three ways:

        You can specify as many splits as you'd like

        (1) Split based on column value (works for pd.DataFrame)
            splits = [
                {"label": "train", "column": "DF_COL", "column_value": 0}, -> "val" can also be a string
                {"label": "test",  "column": "DF_COL", "column_value": 1},
                {"label": "eval",  "column": "DF_COL", "column_value": 2},
                ]

        (2) Index slicing by start and stop (works for np.ndarray, pyarrow.Table, and pd.DataFrame)
            splits = [
                {"label": "train", "start": 0, "stop": 10},
                {"label": "test", "start": 11, "stop": 15},
                ]

        (3) Index slicing by list (works for np.ndarray, pyarrow.Table, and pd.DataFrame)
            splits = [
                {"label": "train", "indices": [1,2,3,4]},
                {"label": "test", "indices": [5,6,7,8]},
                ]

        The following are non-required args and are set after registering a DataCard

        data_uri (str): GCS location where converted pyarrow table is stored
        drift_uri (str): GCS location where drift report is stored
        version (int): DataCard version
        feature_map (dictionary): Map of features in data (inferred when converting to pyrarrow table)
        data_type (str): Data type inferred from supplied data
        uid (str): Unique id assigned to the DataCard


    Returns:
        DataCard

    """

    name: str
    team: str
    user_email: str
    data: Union[np.ndarray, pd.DataFrame, Table]
    drift_report: Optional[Dict[str, DriftReport]] = None
    data_splits: List[Dict[str, Any]] = []
    data_uri: Optional[str] = None
    drift_uri: Optional[str] = None
    version: Optional[int] = None
    feature_map: Optional[Dict[str, Union[str, None]]] = None
    data_type: Optional[str] = None
    uid: Optional[str] = None
    dependent_vars: Optional[List[str]] = None
    feature_descriptions: Optional[Dict[str, str]] = None

    class Config:
        arbitrary_types_allowed = True
        validate_assignment = False

    @property
    def has_data_splits(self):
        return bool(self.data_splits)

    @validator("data_splits", pre=True, always=True)
    def convert_none(cls, splits):  # pylint: disable=no-self-argument
        if splits is None:
            return []

        for split in splits:
            indices = split.get("indices")
            if indices is not None and isinstance(indices, np.ndarray):
                split["indices"] = indices.tolist()

        return splits

    @validator("feature_descriptions", pre=True, always=True)
    def lower_descriptions(cls, feature_descriptions):  # pylint: disable=no-self-argument

        if feature_descriptions is None:
            return feature_descriptions

        feat_dict = {}
        for feature, description in feature_descriptions.items():
            feat_dict[feature.lower()] = description.lower()

        return feat_dict

    def overwrite_converted_data_attributes(self, converted_data: ArrowTable):
        setattr(self, "data_uri", converted_data.storage_uri)
        setattr(self, "feature_map", converted_data.feature_map)
        setattr(self, "data_type", converted_data.table_type)

    def split_data(self) -> Optional[DataHolder]:

        """Loops through data splits and splits data either by indexing or
        column values

        Returns
            Class containing data splits
        """

        if not self.has_data_splits:
            return None

        data_splits: DataHolder = self._parse_data_splits()
        return data_splits

    def _parse_data_splits(self) -> DataHolder:

        data_holder = DataHolder()
        for split in self.data_splits:
            label, data = DataSplitter(split_attributes=split).split(data=self.data)
            setattr(data_holder, label, data)

        return data_holder

    def _convert_and_save_data(self, blob_path: str, version: int) -> None:

        """Converts data into a pyarrow table or numpy array and saves to gcs.

        Args:
            Data_registry (str): Name of data registry. This attribute is used when saving
            data in gcs.
        """

        converted_data: ArrowTable = DataFormatter.convert_data_to_arrow(data=self.data)
        converted_data.feature_map = DataFormatter.create_table_schema(converted_data.table)
        storage_path = save_record_artifact_to_storage(
            artifact=converted_data.table,
            name=self.name,
            version=version,
            team=self.team,
            blob_path=blob_path,
        )
        converted_data.storage_uri = storage_path.gcs_uri

        # manually overwrite
        self.overwrite_converted_data_attributes(converted_data=converted_data)

    def _save_drift(self, blob_path: str, version: int) -> None:

        """Saves drift report to gcs"""

        if bool(self.drift_report):

            storage_path = save_record_artifact_to_storage(
                artifact=self.drift_report,
                name="drift_report",
                version=version,
                team=self.team,
                blob_path=blob_path,
            )
            setattr(self, "drift_uri", storage_path.gcs_uri)

    def create_registry_record(self, registry_name: str, uid: str, version: int) -> DataRegistryRecord:

        """Creates required metadata for registering the current data card.
        Implemented with a DataRegistry object.

        Args:
            Data_registry (str): Name of data registry. This attribute is used when saving
            data in gcs.

        Returns:
            Regsitry metadata

        """
        setattr(self, "uid", uid)
        setattr(self, "version", version)
        self._convert_and_save_data(blob_path=registry_name, version=version)
        self._save_drift(blob_path=registry_name, version=version)

        return DataRegistryRecord(**self.__dict__)


class ModelCard(ArtifactCard):
    """Create a ModelCard from your trained machine learning model.
    This Card is used in conjunction with the ModelCardCreator class.

    Args:
        data (np.ndarray, pd.DataFrame, pa.Table): Data to use for
        data card.
        name (str): What to name the model
        team (str): Team that this model is associated with
        user_email (str): Email to associate with card
        uid (str): Unique id
        version (int): Current version
        data_card_uid (str): Uid of the DataCard associated with training the model
        onnx_model_data (DataDict): Pydantic model containing onnx data schema
        onnx_model_def (ModelDefinition): Pydantic model containing OnnxModel definition
        model_uri (str): GCS uri where model is stored
        model_type (str): Type of model
        data_schema (Dictionary): Optional dictionary of the data schema used in model training
    """

    name: str
    team: str
    user_email: str
    uid: Optional[str] = None
    version: Optional[int] = None
    data_card_uid: Optional[str] = None
    onnx_model_data: DataDict
    onnx_model_def: ModelDefinition
    model_uri: Optional[str]
    model_type: str
    data_schema: Optional[Dict[str, str]]

    class Config:
        arbitrary_types_allowed = True
        keep_untouched = (cached_property,)

    def save_modelcard(self, blob_path: str, version: int):

        storage_path = save_record_artifact_to_storage(
            artifact=self.dict(),
            name=self.name,
            version=version,
            team=self.team,
            blob_path=blob_path,
        )
        setattr(self, "model_uri", storage_path.gcs_uri)

    def _validate_data_card(self, model_registry_name: str) -> None:

        if self.data_card_uid is None:
            raise ValueError(
                """ModelCard is not associated with a DataCard uid. ModelCards
                must be associated with a DataCard prior to registration."""
            )

        registry = DataRegistryChecker(model_registry_name=model_registry_name)
        has_record = registry.validate_data_uid(uid=self.data_card_uid)

        if not has_record:
            raise ValueError(
                """Invalid DataCard uid provided with ModelCard. Please verify correct DataCard.
                """
            )

    def create_registry_record(self, registry_name: str, uid: str, version: int) -> ModelRegistryRecord:
        """Creates a registry record from the current ModelCard

        registry_name (str): ModelCard Registry table making request
        uid (str): Unique id of ModelCard

        """

        self._validate_data_card(model_registry_name=registry_name)

        setattr(self, "uid", uid)
        setattr(self, "version", version)
        self.save_modelcard(blob_path=registry_name, version=version)
        return ModelRegistryRecord(**self.__dict__)

    def _decrypt_model_definition(self) -> bytes:
        cipher = Fernet(key=self.onnx_model_def.encrypt_key)
        model_bytes = cipher.decrypt(self.onnx_model_def.model_bytes)

        return model_bytes

    def _set_version_for_predictor(self) -> int:
        if self.version is None:
            logger.warning(
                """ModelCard has no version (not registered).
                Defaulting to 1 (for testing only)
            """
            )
            version = 1
        else:
            version = self.version

        return version

    def model(self) -> OnnxModelPredictor:

        """Loads a model from serialized string

        Returns
            Onnx ModelProto

        """

        model_bytes = self._decrypt_model_definition()
        version = self._set_version_for_predictor()

        #

        return OnnxModelPredictor(
            model_type=self.model_type,
            model_definition=model_bytes,
            data_dict=self.onnx_model_data,
            data_schema=self.data_schema,
            model_version=version,
        )


class PipelineCard(ArtifactCard):
    name: str
    team: str
    user_email: str
    uid: Optional[str] = None
    version: Optional[int] = None
    data_card_uid: Optional[str] = None
    model_card_uid: Optional[str] = None
    experiment_card_uid: Optional[str] = None


class ExperimentCard(ArtifactCard):
    name: str
    team: str
    user_email: str
    uid: Optional[str] = None
    version: Optional[int] = None
    data_card_uid: Optional[str] = None
    model_card_uid: Optional[str] = None
    pipeline_card_uid: Optional[str] = None
    metrics: Optional[Dict[str, Union[float, int]]] = None
    artifacts: Optional[Dict[str, Any]] = None
    artifact_uris: Optional[Dict[str, str]] = None

    @validator("metrics", pre=True, always=True)
    def set_metrics(cls, value):  # pylint: disable=no-self-argument
        if not value:
            value = {}
            return value
        return value

    @validator("artifacts", pre=True, always=True)
    def set_artifacts(cls, value):  # pylint: disable=no-self-argument
        if not value:
            value = {}
            return value
        return value

    def add_metric(self, name: str, value: Union[int, float]):
        """Adds metric to the existing ExperimentCard metric dictionary

        name (str): Name of metric
        value (float or int): Value of metric
        """

        curr_metrics = cast(Dict[str, Union[int, float]], self.metrics)
        self.metrics = {**{name: value}, **curr_metrics}

    def add_metrics(self, metrics: Dict[str, Union[float, int]]):
        """Adds metrics to the existing ExperimentCard metric dictionary

        metrics (dictionary): Dictionary containing name (str) and value (float or int) pairs
        to add to the current metric set
        """

        curr_metrics = cast(Dict[str, Union[int, float]], self.metrics)
        self.metrics = {**metrics, **curr_metrics}

    def add_artifact(self, name: str, artifact: Any):
        """Append any artifact associated with your experiment to
        the ExperimentCard. The aritfact will be saved in gcs and the uri
        will be appended to the ExperimentCard. Artifact must be pickleable
        (saved with joblib)

        Args:
            name (str): What to name the arifact
            artifact(Any): Artifact to add
        """

        curr_artifacts = cast(Dict[str, Any], self.artifacts)
        new_artifact = {name: artifact}
        self.artifacts = {**new_artifact, **curr_artifacts}

        setattr(self, "artifacts", {**new_artifact, **self.artifacts})

    def save_artifacts(self, blob_path: str, version: int) -> None:

        artifact_uris: Dict[str, str] = {}

        if self.artifacts is not None:
            for name, artifact in self.artifacts.items():
                storage_path = save_record_artifact_to_storage(
                    artifact=artifact,
                    name=self.name,
                    version=version,
                    team=self.team,
                    blob_path=blob_path,
                )

                artifact_uris[name] = storage_path.gcs_uri
        setattr(self, "artifact_uris", artifact_uris)

    def create_registry_record(self, registry_name: str, uid: str, version: int) -> ExperimentRegistryRecord:
        """Creates a registry record from the current ModelCard

        registry_name (str): ModelCard Registry table making request
        uid (str): Unique id of ModelCard

        """

        if not any([self.data_card_uid, self.pipeline_card_uid, self.model_card_uid]):
            raise ValueError(
                """One of DataCard, ModelCard, or PipelineCard must be specified
            """
            )

        setattr(self, "uid", uid)
        setattr(self, "version", version)
        self.save_artifacts(blob_path=registry_name, version=version)
        return ExperimentRegistryRecord(**self.__dict__)
